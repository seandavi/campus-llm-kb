[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Large Language Model Policy and Practice",
    "section": "",
    "text": "1 Overview\nLarge language models, like ChatGPT, have garnered significant interest due to their human-like language generation and immense natural language processing capabilities. These models offer opportunities to revolutionize healthcare by enhancing clinical decision-making, patient care, and medical research. However, implementing them also poses technical, ethical, legal, and social challenges.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#technical-challenges-and-opportunities",
    "href": "index.html#technical-challenges-and-opportunities",
    "title": "Large Language Model Policy and Practice",
    "section": "1.1 Technical Challenges and Opportunities",
    "text": "1.1 Technical Challenges and Opportunities\nDeveloping and implementing large language models entail considerable computational power for training and inference. These models demand extensive data and computational resources, but recent advancements in deep learning frameworks and cloud computing have facilitated their large-scale deployment.\nBias in language models is another technical challenge. Models trained on biased data can produce biased outcomes, potentially leading to incorrect clinical decisions or reinforcing health disparities. Researchers have proposed various techniques to mitigate bias, such as data augmentation, adversarial training, and fairness constraints.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#ethical-challenges-and-opportunities",
    "href": "index.html#ethical-challenges-and-opportunities",
    "title": "Large Language Model Policy and Practice",
    "section": "1.2 Ethical Challenges and Opportunities",
    "text": "1.2 Ethical Challenges and Opportunities\nImplementing large language models in healthcare raises ethical concerns like patient privacy, informed consent, and fairness. Models require vast amounts of data, including personal health information, which can compromise patient privacy and data protection. Patients may also be unaware of how their data is used or may not have provided informed consent.\nConversely, large language models present ethical opportunities. They can generate natural language explanations for clinical decisions, improving transparency and trust between patients and providers. Furthermore, these models can identify and address health disparities by analyzing large-scale data and developing targeted interventions.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#legal-challenges-and-opportunities",
    "href": "index.html#legal-challenges-and-opportunities",
    "title": "Large Language Model Policy and Practice",
    "section": "1.3 Legal Challenges and Opportunities",
    "text": "1.3 Legal Challenges and Opportunities\nLegal challenges include liability and regulatory compliance. If language models contribute to clinical decisions, providers may be held liable for adverse outcomes. Compliance with existing regulations, such as HIPAA, is also crucial.\nOn the other hand, legal opportunities arise from using large language models to analyze extensive healthcare data, identifying potential fraud or abuse, and enhancing healthcare delivery efficiency and effectiveness.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#social-challenges-and-opportunities",
    "href": "index.html#social-challenges-and-opportunities",
    "title": "Large Language Model Policy and Practice",
    "section": "1.4 Social Challenges and Opportunities",
    "text": "1.4 Social Challenges and Opportunities\nSocial challenges involve potential job displacement and exacerbation of healthcare disparities. Language models could automate healthcare jobs and, if biased, reinforce existing disparities, particularly in marginalized communities.\nHowever, social opportunities also emerge, such as improving healthcare accessibility for at-risk or disadvantaged populations and enhancing healthcare service quality through personalized treatment recommendations and identifying areas for improvement in healthcare delivery or clinical operations.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "index.html#use-in-medical-education",
    "href": "index.html#use-in-medical-education",
    "title": "Large Language Model Policy and Practice",
    "section": "1.5 Use in Medical Education",
    "text": "1.5 Use in Medical Education\nLarge language models can also play a significant role in medical education settings. They can assist in developing personalized learning pathways, providing instant feedback on complex clinical scenarios, and facilitating access to a wealth of medical knowledge. By incorporating these models into medical curricula, educators can enhance the learning experience and better prepare future healthcare professionals.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Overview</span>"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface",
    "section": "",
    "text": "This book is a work in progress. It develops a framework for adopting ChatGPT and related tools for the Campus. It is not a complete strategic plan and is not meant to be proscriptive. It is meant to help organize and communicate efforts.\nThe key component of the framework, in my opinion, is the recognition that, while the campus is a single entity, it is composed of four relatively distinct “Domains” that each have their own needs, requirements, resources, and priorities. The four domains that I have identified are:\n\nEducation\nResearch\nBusiness operations\nClinical\n\nThe framework is based on the idea that each of these domains has a different set of needs and requirements, and that the campus should develop plans and implementations that are tailored to each domain. The framework includes a set of “principles” that should be applied to each domain, and a set of “strategies” that should be applied to each domain. The principles and strategies are not meant to be proscriptive, but rather to provide guidance and a framework for thinking about how to approach each domain.\nThe framework is also based on the idea that the campus should adopt a “platform” approach to the development of tools and services. I have included the “platform” concept as a set of identifiable cross-domain workstreams.\nI also note that this framework is not meant to be a “top-down” approach. Rather, it is meant to be a “bottom-up” approach that is driven by the needs of the individual domains. The framework is meant to provide a common language and common set of tools that can be used to develop solutions that meet the needs of the individual domains and the campus as a whole.\nThe framework is also meant to be a living document. It is meant to be updated and revised as new information becomes available and as new needs and requirements are identified. Progress on the framework should be tracked and reported on a regular basis.\nFinally, this framework can form the basis for adoption of any AI (or even other technology) on campus. It is not specific to ChatGPT, though I have found that approaching frameworks with concrete examples is key to success. In that regard, time invested in creating robust processes for ChatGPT will pay dividends in the future as other AI technologies are adopted.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "values.html",
    "href": "values.html",
    "title": "2  Values and Principles",
    "section": "",
    "text": "2.1 Vision Statement",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Values and Principles</span>"
    ]
  },
  {
    "objectID": "values.html#vision-statement",
    "href": "values.html#vision-statement",
    "title": "2  Values and Principles",
    "section": "",
    "text": "LLMs must be used in a manner consistent with the mission, vision, and values of the academic hospital system.\nThe use of LLMs must align with relevant legal and regulatory requirements, including but not limited to data privacy, security, and intellectual property laws.\nThe deployment of LLMs should prioritize patient safety, privacy, and wellbeing.\nLLMs must be used in a transparent manner, with users understanding the capabilities and limitations of the technology.\nContinuous improvement and evaluation of LLM usage should be prioritized to ensure ongoing alignment with organizational goals.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Values and Principles</span>"
    ]
  },
  {
    "objectID": "values.html#stakeholder-considerations",
    "href": "values.html#stakeholder-considerations",
    "title": "2  Values and Principles",
    "section": "2.2 Stakeholder Considerations",
    "text": "2.2 Stakeholder Considerations\n\n2.2.1 Patients\n\nLLMs should be used to augment patient care and improve outcomes, without replacing the human touch and empathy of healthcare providers.\nPatients must be informed about the use of LLMs in their care, and they should have the option to opt out if desired.\nPatient data used in LLM applications must be anonymized, encrypted, and securely stored to protect patient privacy.\n\n\n\n2.2.2 Healthcare Providers\n\nLLMs should be deployed to enhance clinical decision-making and efficiency without undermining the autonomy and expertise of healthcare providers.\nAdequate training and support should be provided to healthcare providers to ensure proper use and understanding of LLMs.\nFeedback from healthcare providers must be regularly solicited to improve LLM performance and usability.\n\n\n\n2.2.3 Researchers\n\nThe use of LLMs in research must adhere to ethical standards, including obtaining informed consent and minimizing potential harm.\nCollaboration between researchers and LLM developers should be encouraged to drive innovation and address specific research needs.\nResearch involving LLMs should be transparent and reproducible, with results and methodologies made available to the wider scientific community.\n\n\n\n2.2.4 Administrators and Support Staff\n\nLLMs should be deployed in administrative and support functions to improve efficiency, reduce costs, and enhance the overall quality of service.\nStaff should receive appropriate training and support to understand and utilize LLMs effectively.\nEmployee feedback should be actively sought to identify areas of improvement and potential new applications for LLMs.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Values and Principles</span>"
    ]
  },
  {
    "objectID": "values.html#monitoring-and-compliance",
    "href": "values.html#monitoring-and-compliance",
    "title": "2  Values and Principles",
    "section": "2.3 Monitoring and Compliance",
    "text": "2.3 Monitoring and Compliance\n\nA designated LLM Steering Committee, comprising representatives from various stakeholder groups, will be responsible for monitoring and enforcing compliance with this policy.\nPeriodic audits and assessments will be conducted to ensure adherence to this policy and identify areas for improvement.\nPolicy violations may result in disciplinary action, up to and including termination of employment or access to LLMs",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Values and Principles</span>"
    ]
  },
  {
    "objectID": "framework.html",
    "href": "framework.html",
    "title": "3  The Framework",
    "section": "",
    "text": "3.1 Domains\nThe implementation plan for integrating AI and Large Language Models into an academic medical system consists of four main domains:",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Framework</span>"
    ]
  },
  {
    "objectID": "framework.html#domains",
    "href": "framework.html#domains",
    "title": "3  The Framework",
    "section": "",
    "text": "Education\nResearch\nClinical\nBusiness Operations\n\n\n3.1.1 Education\nThis domain includes all activities related to teaching, learning, and evaluation within the institution. It also encompasses the development of new educational programs and the management of existing ones.\n\n\n3.1.2 Research\nThis domain focuses on the practice of the basic, clinical, and translational research programs within the institution. In addition, it includes the management of research grants, the development of new research programs, and the dissemination of research findings.\n\n\n3.1.3 Clinical\nThis domain encompasses all activities related to patient care, including the management and implementation of clinical services, decision support and clinical decision-making, automation, and point-of-care or electronic patient support.\n\n\n3.1.4 Business Operations\nThis domain focuses on the management of the institution’s business operations, including finance, human resources, information technology, and facilities management. It also includes the development of new business processes and the management of existing ones.",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Framework</span>"
    ]
  },
  {
    "objectID": "framework.html#workstreams",
    "href": "framework.html#workstreams",
    "title": "3  The Framework",
    "section": "3.2 Workstreams",
    "text": "3.2 Workstreams\nWithin each domain, we have identified five workstreams that are critical for the successful implementation of AI and Large Language Models. These workstreams are:\n\nData Access & Use\nIT, Security, & Infrastructure\nEthical, Legal, & Social\nTraining & Workforce Development\nProject Management & Support Personnel\n\n\n3.2.1 Data Access & Use\nThis workstream focuses on managing and optimizing data access, use, and sharing within the academic medical system. It ensures that data is available, reliable, and secure for AI integration and that the necessary infrastructure is in place to support data-driven activities.\n\n\n3.2.2 IT, Security, & Infrastructure\nThis workstream addresses the technical aspects of AI integration, including the development and maintenance of IT systems, ensuring data security, and providing the necessary hardware and software infrastructure to support AI and Large Language Models.\n\n\n3.2.3 Ethical, Legal, & Social\nThis workstream focuses on the ethical, legal, and social implications of AI integration in the academic medical system with domain-specific focus as appropriate. It aims to ensure that AI is used responsibly and ethically and that any legal and social concerns are addressed proactively.\n\n\n3.2.4 Training & Workforce Development\nThis workstream is dedicated to developing the skills and knowledge of domain community members (including staff and leadership) within the domain to understand and, where appropriate, to effectively use and manage AI and Large Language Models. It includes training programs, workshops, and other educational opportunities to build competency in AI-related technologies.\n\n\n3.2.5 Project Management & Support Personnel\nThis workstream is responsible for ensuring that the project management of AI and Large Language Models across the four domains. Among its roles are to provide project management, helping to align resource requests, support services around the usage of LLMs. This group will also cooordinate support staff who work collaboratively within and across domains to to ensure that AI integration occurs smoothly and efficiently.\nThe implementation plan is structured in a way that allows for cross-functional collaboration between the domains and workstreams. This ensures that AI and Large Language Models are integrated cohesively across the entire academic medical system, maximizing the benefits and minimizing potential risks.",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Framework</span>"
    ]
  },
  {
    "objectID": "implementation.html",
    "href": "implementation.html",
    "title": "4  Domain Implementation Guide",
    "section": "",
    "text": "4.1 Suggested Tasks",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Domain Implementation Guide</span>"
    ]
  },
  {
    "objectID": "implementation.html#suggested-tasks",
    "href": "implementation.html#suggested-tasks",
    "title": "4  Domain Implementation Guide",
    "section": "",
    "text": "4.1.1 Establish Ownership Leadership\nAssign a Domain leader and convene a Domain Working Group (represented in blue boxes in Figure 3.1) as the driving force behind ChatGPT implementation. This leader and Working Group members need to become proficient in the technology and subsequently guide the organization through the process of integration. This includes setting the vision, aligning key stakeholders, and ensuring that the implementation aligns with the organization’s strategic goals.\nIn practice, this Domain leader will be the primary point of contact for the AISC and will be responsible for reporting on the Domain’s progress and deliverables. The Domain leader will also be responsible for convening the Domain Working Group and ensuring that the Domain’s Workstreams are progressing.\n\n\n4.1.2 Lean Into Cross-functional Collaboration\nForm a cross-functional team with representatives from HR, IT, Legal, and other relevant departments to ensure that various perspectives are considered, and organizational needs are met during ChatGPT implementation. This collaboration will help address potential challenges, optimize resources, and facilitate effective knowledge transfer across the organization.\n\n\n4.1.3 Educate Leadership Teams\nKeep leadership teams informed about ChatGPT to enable swift, informed decision-making. Offer workshops and seminars to provide an in-depth understanding of the technology, its potential benefits, and its limitations. This empowers them to make quick, informed decisions that will shape the organization’s adoption and use of the technology.\n\n\n4.1.4 Identify Potential Use Cases\nMap potential applications across all functions and establish a cohesive implementation plan. Conduct thorough analyses of business processes and functions to identify areas where ChatGPT can bring significant value, prioritize these use cases, and create a detailed roadmap for implementation, including timelines and milestones.\n\n\n4.1.5 Craft a Communication Strategy\nDevelop a comprehensive communication strategy that addresses employee concerns and questions about the implementation of ChatGPT. This approach should be transparent, informative, and reassuring to ensure a smooth transition. It should also highlight the benefits of the technology and address potential misconceptions.\n\n\n4.1.6 Prepare and Integrate High-Value Proprietary Datasets\nBuild APIs and interfaces to combine ChatGPT with organization-specific data for improved innovation and efficiency. Invest in the development of custom solutions that seamlessly integrate ChatGPT with existing systems, databases, and workflows to fully harness the potential of the technology.\n\n\n4.1.7 Create Employee Training and Support\nProvide comprehensive training programs that laverage publicly available content where possible for employees to effectively use ChatGPT in their daily work. Offer hands-on workshops, e-learning modules, and on-the-job training to equip employees with the skills and knowledge necessary to use ChatGPT effectively. Provide ongoing support and resources to help employees adapt to the new technology and address any challenges they may face.\n\n\n4.1.8 Monitor Progress and Impact\nRegularly assess the performance of ChatGPT within the organization and evaluate its impact on specific use cases. Develop key performance indicators (KPIs) and metrics to track the technology’s effectiveness, and use this data to inform future improvements and adaptations.\n\n\n4.1.9 Develop Continuous Improvement and Adaptation\nStay current with AI advancements and adapt ChatGPT implementation to maximize benefits. The AI landscape is constantly evolving, and it’s crucial to stay up-to-date with advancements in the field. Continuously evaluate the performance of ChatGPT and be prepared to adapt its implementation to maximize its benefits and stay ahead of the competition.\n\n\n4.1.10 Recognize, Document, and Build Processes to Address Ethical Considerations\nDevelop guidelines for responsible use and educate employees on potential risks and challenges of AI technologies like ChatGPT. Be mindful of the ethical implications of using AI-powered technologies. Develop guidelines and best practices for responsible use, and ensure that employees understand the potential risks and challenges associated with AI, such as algorithmic bias or unintended consequences.\n\n\n\n\nLindegaard, Stefan. 2023. “LinkedIn.” https://www.linkedin.com/pulse/chatgpt-implementation-scaling-organization-your-guide-lindegaard/. https://www.linkedin.com/pulse/chatgpt-implementation-scaling-organization-your-guide-lindegaard/.",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Domain Implementation Guide</span>"
    ]
  },
  {
    "objectID": "barriers.html",
    "href": "barriers.html",
    "title": "5  Barriers and Obstacles and How to Overcome Them",
    "section": "",
    "text": "5.1 Barriers and Obstacles",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Barriers and Obstacles and How to Overcome Them</span>"
    ]
  },
  {
    "objectID": "barriers.html#barriers-and-obstacles",
    "href": "barriers.html#barriers-and-obstacles",
    "title": "5  Barriers and Obstacles and How to Overcome Them",
    "section": "",
    "text": "5.1.1 Resistance to Change\n: Employees and leaders may be resistant to adopting new technologies due to fear of job loss or discomfort with the unknown. To overcome this, emphasize the benefits of ChatGPT, such as increased efficiency and improved decision-making, and provide ample training and support. Encourage open discussions and showcase successful examples of AI adoption.\n\n\n5.1.2 Lack of Technical Expertise\nLimited knowledge of AI and ChatGPT may hinder successful implementation. Address this by investing in training programs, partnering with AI experts, or hiring professionals with relevant experience. Create an internal AI community for knowledge sharing and peer support.\n\n\n5.1.3 Insufficient Collaboration\nInadequate communication and collaboration between departments can impede progress. Foster cross-functional teamwork through regular meetings, workshops, and collaborative platforms. Encourage leaders to champion the initiative and create a culture of cooperation.\n\n\n5.1.4 Resource Constraints\nLimited budget, time, or personnel can pose challenges. To overcome this, prioritize use cases based on potential impact and feasibility, and secure buy-in from top management for necessary resources. Consider leveraging external partnerships or outsourcing certain tasks to reduce internal workload.\n\n\n5.1.5 Data Privacy and Security Concerns\nHandling sensitive proprietary data may raise concerns. Collaborate closely with IT and Legal departments to establish robust data security protocols and comply with regulations. Communicate these measures transparently to build trust among employees and stakeholders.\n\n\n5.1.6 Ethical Concerns\nThe potential for biased or unethical AI outcomes may create apprehension. Develop guidelines for responsible AI usage, create an ethics review board, and offer training on potential risks and challenges. Emphasize the importance of ethical AI practices throughout the organization.\nAs we reflect on the potential barriers and obstacles to ChatGPT implementation, remember that overcoming these challenges is an integral part of the journey towards AI-driven success. By anticipating and addressing these issues proactively, we can foster a resilient and adaptable organization that is well-prepared to navigate the ever-evolving landscape of artificial intelligence.",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Barriers and Obstacles and How to Overcome Them</span>"
    ]
  },
  {
    "objectID": "barriers.html#overcoming-barriers-and-obstacles",
    "href": "barriers.html#overcoming-barriers-and-obstacles",
    "title": "5  Barriers and Obstacles and How to Overcome Them",
    "section": "5.2 Overcoming Barriers and Obstacles",
    "text": "5.2 Overcoming Barriers and Obstacles\nAs noted above, there are many barriers and obstacles to ChatGPT implementation and overcoming these is crucial for realizing its full potential within the organization. \nIn this section, we provide a combination of conventional and less traditional strategies to address the challenges you might face during the adoption process. By embracing these adaptive approaches, we can foster a culture of adaptability and resilience, enabling your organization to successfully harness the power of AI-driven solutions like ChatGPT.\n\n5.2.1 Conventional Strategies for Overcoming Barriers and Obstacles\n\nResistance to Change : To overcome resistance to change, emphasize the benefits of ChatGPT, provide ample training and support, encourage open discussions, and showcase successful examples of AI adoption.\nLack of Technical Expertise : Address this by investing in training programs, partnering with AI experts, hiring professionals with relevant experience, and creating an internal AI community for knowledge sharing and peer support.\nInsufficient Collaboration : Foster cross-functional teamwork through regular meetings, workshops, and collaborative platforms, and encourage leaders to champion the initiative and create a culture of cooperation.\nResource Constraints : Prioritize use cases based on potential impact and feasibility, secure buy-in from top management for necessary resources, and consider leveraging external partnerships or outsourcing certain tasks to reduce internal workload.\nData Privacy and Security Concerns : Collaborate closely with IT and Legal departments to establish robust data security protocols and comply with regulations, and communicate these measures transparently to build trust among employees and stakeholders.\nEthical Concerns : Develop guidelines for responsible AI usage, create an ethics review board, and offer training on potential risks and challenges, emphasizing the importance of ethical AI practices throughout the organization.\n\n\n\n5.2.2 Unconventional Strategies for Overcoming Barriers and Obstacles\nI often find that we need to find “back-doors” and just different approaches in the context of change and transformation projects. Thus, here are some less conventional approaches to the barriers. \n\nGamification : Introduce gamification elements to the training and adoption process, incentivizing employees to engage with ChatGPT and learn its capabilities. Offer rewards or recognition for participation and achievements.\nReverse Mentoring : Encourage younger or more tech-savvy employees to mentor older or less experienced colleagues, facilitating knowledge sharing and promoting a more inclusive approach to technology adoption.\nInnovation Contests : Organize internal contests or hackathons for employees to develop creative ChatGPT use cases or solutions, fostering a sense of ownership and excitement around the technology.\nExternal Showcasing : Publicly share successful ChatGPT implementation stories or use cases to build a positive reputation, attract talent, and create a culture of innovation within the organization.\nAI Sabbaticals : Offer employees the opportunity to take short-term sabbaticals to focus on AI-related projects or training, providing dedicated time for learning and exploration. This can help develop in-house expertise and promote a culture of continuous learning.",
    "crumbs": [
      "Implementation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Barriers and Obstacles and How to Overcome Them</span>"
    ]
  },
  {
    "objectID": "resources_clinical.html",
    "href": "resources_clinical.html",
    "title": "6  Clinical Domain",
    "section": "",
    "text": "6.1 Literature",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Clinical Domain</span>"
    ]
  },
  {
    "objectID": "resources_clinical.html#literature",
    "href": "resources_clinical.html#literature",
    "title": "6  Clinical Domain",
    "section": "",
    "text": "Mandl, K.D., Gottlieb, D. and Mandel, J.C. (2024) ‘Integration of AI in healthcare requires an interoperable digital data ecosystem’, Nature Medicine. Available at: https://doi.org/10.1038/s41591-023-02783-w.\nTierney Aaron A. et al. (no date) ‘Ambient Artificial Intelligence Scribes to Alleviate the Burden of Clinical Documentation’, Catalyst non-issue content, 5(1), p. CAT.23.0404. Available at: https://doi.org/10.1056/CAT.23.0404.",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Clinical Domain</span>"
    ]
  },
  {
    "objectID": "resources_clinical.html#guiding-principles-table",
    "href": "resources_clinical.html#guiding-principles-table",
    "title": "6  Clinical Domain",
    "section": "6.2 Guiding principles table",
    "text": "6.2 Guiding principles table\n\n\n\nTable 6.1: Questions that can be used when considering each principle in the AI development process (Badal, Lee, and Esserman 2023)\n\n\n\n\n\n\n\n\n\nPrinciple\nQuestions\n\n\n\n\n1. Alleviate healthcare disparities\n• What health disparities are reported for the present AI application?• How can the AI tool be designed to be accessible to and improve outcomes for the disadvantaged population?• What clinical interventions are needed to realize the benefit, and are these accessible?• How can data collection be supported in underserved communities for tool retraining over time?\n\n\n2. Report clinically meaningful outcomes\n• How is clinical benefit defined in this domain?• What is the present threshold for the clinical benefit of existing tools, and how can the AI tool improve upon this threshold?\n\n\n3. Reduce overdiagnosis and overtreatment\n• What disease state is an overdiagnosis?• For every case of overdiagnosis, what are the downstream costs to the patient and healthcare system?• How can this AI application reduce the number of overdiagnoses compared to existing approaches?\n\n\n4. Have high healthcare value\n• Is this AI tool addressing a high-priority healthcare need?• What would be the cost to the healthcare system in implementation, maintenance, and update?• What would be the cost to the patient who does and does not benefit from this tool?• Does this tool have high healthcare value, and if not, how can it be improved?\n\n\n5. Incorporate biography\n• What biographical data can be collected or carefully coded for the intended population?• How do these factors vary in the intended population?• How can these factors be included when developing AI tools?\n\n\n6. Be easily tailored to the local population\n• Can the training features be easily collected in different settings?• Are these features reliable for training across different populations?• Will the AI/ML workflow be made open-access?\n\n\n7. Promote a learning healthcare system\n• How will this AI application be evaluated over time, and at what intervals?• What are acceptable thresholds for performance?• How will the evaluation results contribute to continuous improvement?\n\n\n8. Facilitate shared decision-making\n• Have AI explainability tools been explored and utilized?• Do clinicians and patients find the explainability results helpful?• Have simpler, explainable algorithms been tried and compared to ‘black-box’ algorithms to determine if a simpler model performs just as well?• How can patient values be easily integrated into the use of the AI tool?\n\n\n\n\n\n\n\n6.2.1 Principle 1: AI tools should aim to alleviate existing health disparities\nReaching health equity requires eliminating the disparitities in health outcomes that are closely linked with social, economic, and environmental disadvantages. At their very core, AI tools require collection of specialized and high-quality data, advanced computing infrastructure for use, capacity to purchase or partner models from commercial entities, and unique technical expertise, all of which are less likely available to healthcare systems that serve the most disadvantaged populations.\nMore careful training and model development that accounts for the unique needs of disadvantaged populations is needed to ensure that AI tools do not exacerbate existing health disparities. Creating equitable AI tools may require prioritizing simpler models for deployment, and the trade-off between balancing accuracy and equity can potentially be resolved by designing AI tools that can be easily tailored to the local population. AI tools designed to serve disadvantaged groups must not unnecessarily divert resources from higher priority areas and more effective interventions (Principle 4).\n\n\n6.2.2 Principle 2: AI tools should produce clinically meaningful outcomes\nAI tools should be evaluated based on their ability to improve clinically meaningful outcomes. The clinical benefit of AI tools should be defined in the context of the existing standard of care, and the AI tool should be evaluated against this standard. If AI practitioners do not define clinical metrics for clinical benefit a priori, they risk producing tools that clinicians cannot evaluate or use. Clinician partners of AI researchers should evaluate accuracy, fairness, and risks of overdiagnosis and overtreatment (Principle 3). They should also evaluate the healthcare value (Principle 4) along with the explainability and auditability of AI tools and models (note principles outlined in Table 6.1.\n\n\n6.2.3 Principle 3: AI tools should reduce overdiagnosis and overtreatment\nParticularly in the United States, overdiagnosis and overtreatment are major drivers of healthcare costs and patient harm. Overdiagnosis occurs when a disease is diagnosed that would not have caused symptoms or death in a patient’s lifetime. Overtreatment occurs when a patient is treated for a disease that would not have caused symptoms or death in a patient’s lifetime. AI tools should be carefully constructed with the spectrum of disease and interventions to result in decreased overdiagnosis and overtreatment.\n\n\n6.2.4 Principle 4: AI tools should have high healthcare value and avoid diverting\nresources from higher-priority areas\nAI tools applied in healthcare should result in the same outcomes for reduced cost or better outcomes for costs comparable to current costs. Costs to gather inputs, build, maintain, update, interpret, and deploy in clinical practice must be estimated and included in weighing the decisions around AI tool application. Note that what might be cost-effective, leading to high healthcare value, in one setting might be extremely cost-ineffective in settings where resources are scarce.\n\n\n6.2.5 Principle 5: AI tools should incorporate social, structural, environmental,\nemotional, and psychological drivers of health\n\n\n6.2.6 Principle 6: AI tools should be easily tailored to the local population\n\n\n6.2.7 Principle 7: AI tools should promote a learning healthcare system\n\n\n6.2.8 Principle 8: AI tools should facilitate shared decision-making\n\n\n\n\nBadal, Kimberly, Carmen M Lee, and Laura J Esserman. 2023. “Guiding Principles for the Responsible Development of Artificial Intelligence Tools for Healthcare.” Communication & Medicine 3 (1): 47. https://doi.org/10.1038/s43856-023-00279-9.",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Clinical Domain</span>"
    ]
  },
  {
    "objectID": "resources_education.html",
    "href": "resources_education.html",
    "title": "8  Education",
    "section": "",
    "text": "8.1 Journals",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#journals",
    "href": "resources_education.html#journals",
    "title": "8  Education",
    "section": "",
    "text": "Computers and Education: Artificial Intelligence",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#basics-and-background",
    "href": "resources_education.html#basics-and-background",
    "title": "8  Education",
    "section": "8.2 Basics and Background",
    "text": "8.2 Basics and Background\n\nCornell University resources for educators\nVanderbilt University Guide to Teaching in the Age of AI\nUniversity of South Carolina ChatGPT for Teaching and Learning\nGenerative Artificial Intelligence in Education and Pedagogy\nOpenAI’s Guidelines for Educators\nAI Guidance from the Poorvu Center at Yale\nNew Jersey Institute of Technology AI and Instruction Guide\nChatting about ChatGPT: How May AI and ChatGPT Impact Academia and Libraries?\nTalking about Large Language Models\nSFCC Comprehensive ChatGPT Resource Guide\nBig Data Big Design\n4 Steps to Help You Plan for ChatGPT in Your Classroom\nCarnegie Mellon University’s FAQ on AI in education\nAI in Higher Education Resource Hub",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#ai-in-the-classroom",
    "href": "resources_education.html#ai-in-the-classroom",
    "title": "8  Education",
    "section": "8.3 AI in the Classroom",
    "text": "8.3 AI in the Classroom\nThis section includes resources that provide insight into the use of AI in the classroom. These resources are intended to provide instructors with a starting point for considering how to use AI in their courses.\n\nDavis Institute for Artificial Intelligence\nThinking about updating your syllabus for Chat GPT?\nTurn It In: Academic Resources in the Age of AI\nIntentional Teaching: Rethinking Teaching in an Age of AI\nIntroduction to AI for Teachers and Students\nUsing AI to Implement Effective Teaching Strategies in Classrooms\nNew Modes of Learning Enabled by AI Chatbots\nTim Laquintano’s forthcoming work\nPractical Responses to ChatGPT and Other Generative AI\nWorld Economic Forum on ChatGPT and Cheating\nHow to Cheat on Your Final Paper: Assigning AI for Student Writing\nAI-Based Text Generation and the Social Construction of “Fraudulent Authorship”\nAI Text Generators and Teaching Writing: Starting Points for Inquiry\nCollaborating with ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education\nWill ChatGPT Change How Professors Access Learning?\nCharles Knight on AI in Higher Ed\nCivics of Technology",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#educational-policy-statements-and-guidelines",
    "href": "resources_education.html#educational-policy-statements-and-guidelines",
    "title": "8  Education",
    "section": "8.4 Educational policy statements and guidelines",
    "text": "8.4 Educational policy statements and guidelines\nThis section includes examples of policy statements and guidelines from institutions of higher education. These examples are intended to provide a starting point for instructors and administrators who are considering how to address the use of generative AI tools in their courses.\n\nCarnegie Mellon University Examples of AI use policies for educators\nUniversity of Iowa, Office of Teaching, Learning, and Technology\nSFCC Library Faculty Help\nCleveland State University Center for Faculty Excellence\nClassroom Policies Related to ChatGPT and Other AI Tools\nMontclair State University AI Course Policies and Assignment Guidelines\nInside HigherEd Opinion Piece on Generative AI Policy Making\nStanford\nDuke and here\nUniversity of Wisconsin-Madison\nNotre Dame\nBoise Statue University\nOSU’s AI: Considerations for Teaching and Learning\nU of Maine’s Learn with AI\nsentientsyllabus.org)\nUpdate Your Syllabus for ChatGPT\nRules for Tools (from Padagogische Hochschule Heidelberg)\nUNESCO",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#bias-and-ethics-in-ai",
    "href": "resources_education.html#bias-and-ethics-in-ai",
    "title": "8  Education",
    "section": "8.5 Bias and Ethics in AI",
    "text": "8.5 Bias and Ethics in AI\n\nHow ChatGPT Could Help or Hurt Students with Disabilities\nAssociation for Progressive Communications\nAlgorithms of Oppression: How Search Engines Reinforce Racism — Safiya Umoja Noble\nRace After Technology: Abolitionist Tools for the New Jim Code\nNIST on Bias in AI\nDecolonial AI: Decolonial Theory as Sociotechical Foresight in Artificial Intelligence",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "resources_education.html#podcasts-and-newsletters-for-further-insight",
    "href": "resources_education.html#podcasts-and-newsletters-for-further-insight",
    "title": "8  Education",
    "section": "8.6 Podcasts and Newsletters for Further Insight",
    "text": "8.6 Podcasts and Newsletters for Further Insight\nIn this section are links to podcasts and newsletters around generative AI and education.\n\nTHE Podcast: How to Use Generative AI in Your Teaching and Research\nForward Thinking on the Brave New World of Generative AI with Ethan Mollick\nWe Can’t Predict How AI Will Change the World\nChatGPT and Good Intentions in Higher Ed\nTea for Teaching: ChatGPT\nWNYC Studios on the Media: It’s a Machine’s World\nCollege of Charleston Podcast: ChatGPT and Conversational AI Explained\nUniversity of Florida’s AI Radio Minutes\nEthan Mollick’s Newsletter: One Useful Thing\nBryan Alexander’s Newsletter: AI and Academia",
    "crumbs": [
      "Domain Resources",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Education</span>"
    ]
  },
  {
    "objectID": "appendices.html",
    "href": "appendices.html",
    "title": "Appendix A — AI principles proposed by select organizations",
    "section": "",
    "text": "This list is adapted from Badal, Lee, and Esserman (2023), Table 1.\n\nEthics and governance of artificial intelligence for health, World Health Organization\n\nHuman autonomy\nHuman well-being and safety and the public interest\nTransparency, explainability, and intelligibility\nResponsibility and accountability\nInclusiveness and equity\nResponsive and sustainable\n\nMinistries of Health, Medical AI algorithm assessment checklist, FUTURE-AI (an international, multi-stakeholder consortium)\n\nFairness\nUniversality\nTraceability\nUsability\nRobustness\nExplainability\n\nGood Machine Learning Practice for Medical Device Development: Guiding Principles, fdFDA, Health Canada, United Kingdom’s Medicines and Healthcare products Regulatory Agency (MHRA)\n\nLeverage multidisciplinary expertise in development\nImplement good software engineering and security practices\nDatasets are representative of intended population\nTraining and test sets are independent\nReference datasets are well developed\nOptimize performance of Human-AI Team\nThorough clinical testing\nInformation accessible to users\nMonitor deployed models and mitigate retraining risk\n\nDefining AMIA’s artificial intelligence principles, American Medical Informatics Association (AMIA)\n\nAutonomy\nBeneficence\nNon-maleficence\nJustice\nExplainability\nInterpretability\nFairness\nDependability\nAuditability\nKnowledge managemen\n\n\n\n\n\n\nBadal, Kimberly, Carmen M Lee, and Laura J Esserman. 2023. “Guiding Principles for the Responsible Development of Artificial Intelligence Tools for Healthcare.” Communication & Medicine 3 (1): 47. https://doi.org/10.1038/s43856-023-00279-9.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>AI principles proposed by select organizations</span>"
    ]
  },
  {
    "objectID": "bill_of_rights.html",
    "href": "bill_of_rights.html",
    "title": "Appendix B — Whitehouse AI Bill(s) of rights",
    "section": "",
    "text": "B.1 Commentary and references",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Whitehouse AI Bill(s) of rights</span>"
    ]
  },
  {
    "objectID": "bill_of_rights.html#commentary-and-references",
    "href": "bill_of_rights.html#commentary-and-references",
    "title": "Appendix B — Whitehouse AI Bill(s) of rights",
    "section": "",
    "text": "Opportunities and blind spots in the White House’s blueprint for an AI Bill of Rights\n6 Reactions to the White House’s AI Bill of Rights The nonbinding principles are being both celebrated and vilified\nApplying the Blueprint for an AI Bill of Rights\n\nHow Does the White House AI Bill of Rights Apply to Healthcare?\n\nExperts from Mayo Clinic Platform and DLA Piper weigh in on how the White House’s Blueprint for an AI Bill of Rights may impact healthcare and health AI regulation.\n\n\nThe US AI Bill Of Rights Should Kickstart The Debate On Bias In Artificial Intelligence",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Whitehouse AI Bill(s) of rights</span>"
    ]
  },
  {
    "objectID": "HHS.html",
    "href": "HHS.html",
    "title": "Appendix C — HHS EHR reporting program rule",
    "section": "",
    "text": "https://www.federalregister.gov/documents/2024/01/09/2023-28857/health-data-technology-and-interoperability-certification-program-updates-algorithm-transparency-and\n\nThis final rule implements the Electronic Health Record (EHR) Reporting Program provision of the 21st Century Cures Act by establishing new Conditions and Maintenance of Certification requirements for health information technology (health IT) developers under the ONC Health IT Certification Program (Program). This final rule also makes several updates to certification criteria and standards recognized by the Program. The Program updates include revised certification criteria for “decision support interventions,” “patient demographics and observations,” and “electronic case reporting,” as well as a new baseline version of the United States Core Data for Interoperability (USCDI) standard to Version 3. Additionally, this final rule provides enhancements to support information sharing under the information blocking regulations. The implementation of these provisions advances interoperability, improves algorithm transparency, and supports the access, exchange, and use of electronic health information (EHI). This final rule also updates numerous technical standards in the Program in additional ways to advance interoperability, enhance health IT certification, and reduce burden and costs for health IT developers and users of health IT.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>HHS EHR reporting program rule</span>"
    ]
  },
  {
    "objectID": "domainresource.html",
    "href": "domainresource.html",
    "title": "Domain Resources",
    "section": "",
    "text": "This section contains resources that the domain teams may find useful for their specific domains.\n\nEducation\nClinical\nResearch\nBusiness Operations",
    "crumbs": [
      "Domain Resources"
    ]
  }
]